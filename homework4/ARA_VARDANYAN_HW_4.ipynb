{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5db52556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d252ae",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ee349405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing data\n",
    "X = np.arange(0,31)\n",
    "Y = np.array([30, 35, 33, 32, 34, 37, 39, 38, 36, 36, 37, 39, 42, 45, 45, 41, 40, 39, 42, 44, 47, 49, 50, 49, 46, 48, 50, 53, 55, 54, 53])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260ae033",
   "metadata": {},
   "source": [
    "### (i) Fit the data to a three layer feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e1d99f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the neural network class\n",
    "class ThreeLayerNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ThreeLayerNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.layer3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "def train_network(model, X_train, Y_train, epochs, learning_rate):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        inputs = Variable(X_train)\n",
    "        targets = Variable(Y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "def evaluate_least_squares_loss(model, X_train, Y_train, X_test, Y_test):\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_outputs = model(X_train)\n",
    "        train_mse = criterion(train_outputs, Y_train)\n",
    "        test_outputs = model(X_test)\n",
    "        test_mse = criterion(test_outputs, Y_test)\n",
    "\n",
    "    train_least_squares_error = torch.sqrt(train_mse).item()\n",
    "    test_least_squares_error = torch.sqrt(test_mse).item()\n",
    "\n",
    "    return train_least_squares_error, test_least_squares_error\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    mae = torch.mean(torch.abs(y_true - y_pred))\n",
    "    return 1 - mae.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7486c",
   "metadata": {},
   "source": [
    "### (ii) Using the first 20 data points as training data, fit the neural network. Compute the least-square error for each of these over the training points. Then compute the least square error of these models on the test data which are the remaining 10 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7b527d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "X = X.reshape(-1, 1)\n",
    "Y = Y.reshape(-1, 1)\n",
    "\n",
    "X = X / 31\n",
    "Y = Y / 55\n",
    "\n",
    "# Creating the training and test sets\n",
    "X_train_extrap = X[:20]\n",
    "Y_train_extrap = Y[:20]\n",
    "X_test_extrap = X[20:]\n",
    "Y_test_extrap = Y[20:]\n",
    "\n",
    "# Converting the data to pytorch tensors\n",
    "X_train_tensor_extrap = torch.FloatTensor(X_train_extrap)\n",
    "Y_train_tensor_extrap = torch.FloatTensor(Y_train_extrap)\n",
    "X_test_tensor_extrap = torch.FloatTensor(X_test_extrap)\n",
    "Y_test_tensor_extrap = torch.FloatTensor(Y_test_extrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "617709ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.0016041655326262116\n",
      "Epoch: 200, Loss: 0.0014134616358205676\n",
      "Epoch: 300, Loss: 0.0013217905070632696\n",
      "Epoch: 400, Loss: 0.001248661894351244\n",
      "Epoch: 500, Loss: 0.0011748403776437044\n",
      "Epoch: 600, Loss: 0.0010809521190822124\n",
      "Epoch: 700, Loss: 0.0009588543325662613\n",
      "Epoch: 800, Loss: 0.0008379902574233711\n",
      "Epoch: 900, Loss: 0.0007454089354723692\n",
      "Epoch: 1000, Loss: 0.0006987500237300992\n"
     ]
    }
   ],
   "source": [
    "# Training the neural network\n",
    "input_size = 1\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "model = ThreeLayerNN(input_size, hidden_size, output_size)\n",
    "\n",
    "train_network(model, X_train_tensor_extrap, Y_train_tensor_extrap, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e8da66ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss (Extrapolation): 0.0263\n",
      "Test Loss (Extrapolation): 0.1827\n",
      "Training Accuracy (Extrapolation): 97.9064%\n",
      "Test Accuracy (Extrapolation): 82.5943%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the loss and accuracy\n",
    "train_loss, test_loss = evaluate_least_squares_loss(model, X_train_tensor_extrap, Y_train_tensor_extrap, X_test_tensor_extrap, Y_test_tensor_extrap)\n",
    "train_accuracy = compute_accuracy(Y_train_tensor_extrap, model(X_train_tensor_extrap))\n",
    "test_accuracy = compute_accuracy(Y_test_tensor_extrap, model(X_test_tensor_extrap))\n",
    "\n",
    "print(f'Training Loss (Extrapolation): {round(train_loss, 4)}')\n",
    "print(f'Test Loss (Extrapolation): {round(test_loss, 4)}')\n",
    "print(f'Training Accuracy (Extrapolation): {round(train_accuracy * 100, 4)}%')\n",
    "print(f'Test Accuracy (Extrapolation): {round(test_accuracy * 100, 4)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8783ab",
   "metadata": {},
   "source": [
    "### (iii) Repeat (ii) but use the first 10 and last 10 data points as training data. Then fit the model to the test data (which are the 10 held out middle data points). Compare these results to (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "92589873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training and test sets\n",
    "X_train_interp = np.concatenate((X[:10], X[-10:]))\n",
    "Y_train_interp = np.concatenate((Y[:10], Y[-10:]))\n",
    "X_test_interp = X[10:20]\n",
    "Y_test_interp = Y[10:20]\n",
    "\n",
    "# Converting the data to pytorch tensors\n",
    "X_train_tensor_interp = torch.FloatTensor(X_train_interp)\n",
    "Y_train_tensor_interp = torch.FloatTensor(Y_train_interp)\n",
    "X_test_tensor_interp = torch.FloatTensor(X_test_interp)\n",
    "Y_test_tensor_interp = torch.FloatTensor(Y_test_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2bcde903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.0011257014703005552\n",
      "Epoch: 200, Loss: 0.001104111666791141\n",
      "Epoch: 300, Loss: 0.0010807627113536\n",
      "Epoch: 400, Loss: 0.0010470146080479026\n",
      "Epoch: 500, Loss: 0.0010048819240182638\n",
      "Epoch: 600, Loss: 0.0009732529288157821\n",
      "Epoch: 700, Loss: 0.0009528251248411834\n",
      "Epoch: 800, Loss: 0.0009335579234175384\n",
      "Epoch: 900, Loss: 0.0009110727114602923\n",
      "Epoch: 1000, Loss: 0.0008885601419024169\n"
     ]
    }
   ],
   "source": [
    "# Training the neural network for interpolation\n",
    "model_interp = ThreeLayerNN(input_size, hidden_size, output_size)\n",
    "\n",
    "train_network(model_interp, X_train_tensor_interp, Y_train_tensor_interp, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ce6f9e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss (Interpolation): 0.0298\n",
      "Test Loss (Interpolation): 0.0553\n",
      "Training Accuracy (Interpolation): 97.3836%\n",
      "Test Accuracy (Interpolation): 95.0551%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the loss and accuracy\n",
    "train_loss_interp, test_loss_interp = evaluate_least_squares_loss(model_interp, X_train_tensor_interp, Y_train_tensor_interp, X_test_tensor_interp, Y_test_tensor_interp)\n",
    "train_accuracy_interp = compute_accuracy(Y_train_tensor_interp, model_interp(X_train_tensor_interp))\n",
    "test_accuracy_interp = compute_accuracy(Y_test_interp_tensor, model_interp(X_test_tensor_interp))\n",
    "\n",
    "print(f'Training Loss (Interpolation): {round(train_loss_interp, 4)}')\n",
    "print(f'Test Loss (Interpolation): {round(test_loss_interp, 4)}')\n",
    "print(f'Training Accuracy (Interpolation): {round(train_accuracy_interp * 100, 4)}%')\n",
    "print(f'Test Accuracy (Interpolation): {round(test_accuracy_interp * 100, 4)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05551589",
   "metadata": {},
   "source": [
    "### (iv) Compare the models fit in homework one to the neural networks in (ii) and (iii)\n",
    "\n",
    "Comparison can be found in the homework4 report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f5cd13",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "93d79813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the neural network\n",
    "\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    total = y_true.size(0)\n",
    "    correct = (predicted == y_true).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "def train_network(model, train_loader, epochs, learning_rate):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs = Variable(inputs)\n",
    "            targets = Variable(targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "def evaluate_loss_accuracy(model, data_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs = Variable(inputs)\n",
    "            targets = Variable(targets)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total += targets.size(0)\n",
    "            correct += (torch.max(outputs, 1)[1] == targets).sum().item()\n",
    "\n",
    "    return total_loss / len(data_loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7cb240d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "X_train = train_dataset.data.numpy()\n",
    "X_test = test_dataset.data.numpy()\n",
    "\n",
    "# Flatten the images\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b82ce",
   "metadata": {},
   "source": [
    "### (i) Compute the first 20 PCA modes of the digit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fe227012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the first 20 PCA modes\n",
    "pca = PCA(n_components=20)\n",
    "pca.fit(X_train_flat)\n",
    "X_train_pca = pca.transform(X_train_flat)\n",
    "X_test_pca = pca.transform(X_test_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154a311",
   "metadata": {},
   "source": [
    "### (ii) Classify the digits with the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "647d9529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.264059454202652\n",
      "Epoch: 20, Loss: 0.8404315114021301\n",
      "Epoch: 30, Loss: 0.23342067003250122\n",
      "Epoch: 40, Loss: 0.10142076760530472\n",
      "Epoch: 50, Loss: 0.08207272738218307\n"
     ]
    }
   ],
   "source": [
    "# Convert the PCA data to tensors\n",
    "X_train_pca_tensor = torch.FloatTensor(X_train_pca)\n",
    "X_test_pca_tensor = torch.FloatTensor(X_test_pca)\n",
    "Y_train_tensor = torch.LongTensor(train_dataset.targets)\n",
    "Y_test_tensor = torch.LongTensor(test_dataset.targets)\n",
    "\n",
    "train_pca_dataset = torch.utils.data.TensorDataset(X_train_pca_tensor, Y_train_tensor)\n",
    "test_pca_dataset = torch.utils.data.TensorDataset(X_test_pca_tensor, Y_test_tensor)\n",
    "train_pca_loader = torch.utils.data.DataLoader(train_pca_dataset, batch_size=100, shuffle=True)\n",
    "test_pca_loader = torch.utils.data.DataLoader(test_pca_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "input_size = 20\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "learning_rate = 0.001\n",
    "epochs = 50\n",
    "\n",
    "# Create and train the model\n",
    "model = FFNN(input_size, hidden_size, output_size)\n",
    "\n",
    "train_network(model, train_pca_loader, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5b0f6eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1844\n",
      "Test Loss: 0.2654\n",
      "Training Accuracy: 96.775%\n",
      "Test Accuracy: 96.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the loss and accuracy\n",
    "train_loss, train_accuracy = evaluate_loss_accuracy(model, train_pca_loader)\n",
    "test_loss, test_accuracy = evaluate_loss_accuracy(model, test_pca_loader)\n",
    "\n",
    "print(f'Training Loss: {round(train_loss, 4)}')\n",
    "print(f'Test Loss: {round(test_loss, 4)}')\n",
    "print(f'Training Accuracy: {round(train_accuracy * 100, 4)}%')\n",
    "print(f'Test Accuracy: {round(test_accuracy * 100, 4)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac60c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
